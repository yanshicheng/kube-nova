// Code generated by goctl. DO NOT EDIT.
// versions:
//  goctl version: 1.7.3

package model

import (
	"context"
	"database/sql"
	"fmt"
	"strings"
	"time"

	"github.com/zeromicro/go-zero/core/stores/builder"
	"github.com/zeromicro/go-zero/core/stores/cache"
	"github.com/zeromicro/go-zero/core/stores/sqlc"
	"github.com/zeromicro/go-zero/core/stores/sqlx"
	"github.com/zeromicro/go-zero/core/stringx"
)

var (
	onecProjectClusterFieldNames          = builder.RawFieldNames(&OnecProjectCluster{})
	onecProjectClusterRows                = strings.Join(onecProjectClusterFieldNames, ",")
	onecProjectClusterRowsExpectAutoSet   = strings.Join(stringx.Remove(onecProjectClusterFieldNames, "`id`", "`create_at`", "`create_time`", "`created_at`", "`update_at`", "`update_time`", "`updated_at`"), ",")
	onecProjectClusterRowsWithPlaceHolder = strings.Join(stringx.Remove(onecProjectClusterFieldNames, "`id`", "`create_at`", "`create_time`", "`created_at`", "`update_at`", "`update_time`", "`updated_at`"), "=?,") + "=?"

	cacheIkubeopsOnecProjectClusterIdPrefix                   = "cache:ikubeops:onecProjectCluster:id:"
	cacheIkubeopsOnecProjectClusterClusterUuidProjectIdPrefix = "cache:ikubeops:onecProjectCluster:clusterUuid:projectId:"
)

type (
	onecProjectClusterModel interface {
		Insert(ctx context.Context, data *OnecProjectCluster) (sql.Result, error)

		FindOne(ctx context.Context, id uint64) (*OnecProjectCluster, error)
		Search(ctx context.Context, orderStr string, isAsc bool, page, pageSize uint64, queryStr string, args ...any) ([]*OnecProjectCluster, uint64, error)
		SearchNoPage(ctx context.Context, orderStr string, isAsc bool, queryStr string, args ...any) ([]*OnecProjectCluster, error)
		FindOneByClusterUuidProjectId(ctx context.Context, clusterUuid string, projectId uint64) (*OnecProjectCluster, error)
		Update(ctx context.Context, data *OnecProjectCluster) error
		Delete(ctx context.Context, id uint64) error
		DeleteSoft(ctx context.Context, id uint64) error
		TransCtx(ctx context.Context, fn func(context.Context, sqlx.Session) error) error
		TransOnSql(ctx context.Context, session sqlx.Session, id uint64, sqlStr string, args ...any) (sql.Result, error)
		ExecSql(ctx context.Context, id uint64, sqlStr string, args ...any) (sql.Result, error)
	}

	defaultOnecProjectClusterModel struct {
		sqlc.CachedConn
		table string
	}

	OnecProjectCluster struct {
		Id                        uint64    `db:"id"`                          // 主键，自增 ID
		ClusterUuid               string    `db:"cluster_uuid"`                // 关联的集群 ID
		ProjectId                 uint64    `db:"project_id"`                  // 关联的项目 ID
		CpuLimit                  string    `db:"cpu_limit"`                   // 上级分配的 CPU 配额（核心数）
		CpuOvercommitRatio        float64   `db:"cpu_overcommit_ratio"`        // CPU 超分比例
		CpuCapacity               string    `db:"cpu_capacity"`                // CPU 超分后总容量 (limit * overcommit_ratio)
		CpuAllocated              string    `db:"cpu_allocated"`               // 已分配给工作空间的 CPU 总量
		MemLimit                  string    `db:"mem_limit"`                   // 上级分配的内存配额（单位：GiB）
		MemOvercommitRatio        float64   `db:"mem_overcommit_ratio"`        // 内存超分比例
		MemCapacity               string    `db:"mem_capacity"`                // 内存超分后总容量 (limit * overcommit_ratio)
		MemAllocated              string    `db:"mem_allocated"`               // 已分配给工作空间的内存总量
		StorageLimit              string    `db:"storage_limit"`               // 存储配额上限（单位：GiB）
		StorageAllocated          string    `db:"storage_allocated"`           // 已分配给工作空间的存储总量
		GpuLimit                  string    `db:"gpu_limit"`                   // 上级分配的 GPU 配额（个数）
		GpuOvercommitRatio        float64   `db:"gpu_overcommit_ratio"`        // GPU 超分比例
		GpuCapacity               string    `db:"gpu_capacity"`                // GPU 超分后总容量 (limit * overcommit_ratio)
		GpuAllocated              string    `db:"gpu_allocated"`               // 已分配给工作空间的 GPU 总量
		PodsLimit                 int64     `db:"pods_limit"`                  // Pod 配额上限
		PodsAllocated             int64     `db:"pods_allocated"`              // 已分配给工作空间的 Pod 总量
		ConfigmapLimit            int64     `db:"configmap_limit"`             // ConfigMap 配额上限
		ConfigmapAllocated        int64     `db:"configmap_allocated"`         // 已分配给工作空间的 ConfigMap 总量
		SecretLimit               int64     `db:"secret_limit"`                // Secret 配额上限
		SecretAllocated           int64     `db:"secret_allocated"`            // 已分配给工作空间的 Secret 总量
		PvcLimit                  int64     `db:"pvc_limit"`                   // PVC 配额上限
		PvcAllocated              int64     `db:"pvc_allocated"`               // 已分配给工作空间的 PVC 总量
		EphemeralStorageLimit     string    `db:"ephemeral_storage_limit"`     // 临时存储配额上限（单位：GiB）
		EphemeralStorageAllocated string    `db:"ephemeral_storage_allocated"` // 已分配给工作空间的临时存储总量
		ServiceLimit              int64     `db:"service_limit"`               // Service 配额上限
		ServiceAllocated          int64     `db:"service_allocated"`           // 已分配给工作空间的 Service 总量
		LoadbalancersLimit        int64     `db:"loadbalancers_limit"`         // LoadBalancer 配额上限
		LoadbalancersAllocated    int64     `db:"loadbalancers_allocated"`     // 已分配给工作空间的 LoadBalancer 总量
		NodeportsLimit            int64     `db:"nodeports_limit"`             // NodePort 配额上限
		NodeportsAllocated        int64     `db:"nodeports_allocated"`         // 已分配给工作空间的 NodePort 总量
		DeploymentsLimit          int64     `db:"deployments_limit"`           // Deployment 配额上限
		DeploymentsAllocated      int64     `db:"deployments_allocated"`       // 已分配给工作空间的 Deployment 总量
		JobsLimit                 int64     `db:"jobs_limit"`                  // Job 配额上限
		JobsAllocated             int64     `db:"jobs_allocated"`              // 已分配给工作空间的 Job 总量
		CronjobsLimit             int64     `db:"cronjobs_limit"`              // CronJob 配额上限
		CronjobsAllocated         int64     `db:"cronjobs_allocated"`          // 已分配给工作空间的 CronJob 总量
		DaemonsetsLimit           int64     `db:"daemonsets_limit"`            // DaemonSet 配额上限
		DaemonsetsAllocated       int64     `db:"daemonsets_allocated"`        // 已分配给工作空间的 DaemonSet 总量
		StatefulsetsLimit         int64     `db:"statefulsets_limit"`          // StatefulSet 配额上限
		StatefulsetsAllocated     int64     `db:"statefulsets_allocated"`      // 已分配给工作空间的 StatefulSet 总量
		IngressesLimit            int64     `db:"ingresses_limit"`             // Ingress 配额上限
		IngressesAllocated        int64     `db:"ingresses_allocated"`         // 已分配给工作空间的 Ingress 总量
		CreatedBy                 string    `db:"created_by"`                  // 记录创建人
		UpdatedBy                 string    `db:"updated_by"`                  // 记录最后更新人
		CreatedAt                 time.Time `db:"created_at"`                  // 记录创建时间
		UpdatedAt                 time.Time `db:"updated_at"`                  // 记录更新时间
		IsDeleted                 int64     `db:"is_deleted"`                  // 是否已删除，软删除标记
	}
)

func newOnecProjectClusterModel(conn sqlx.SqlConn, c cache.CacheConf, opts ...cache.Option) *defaultOnecProjectClusterModel {
	return &defaultOnecProjectClusterModel{
		CachedConn: sqlc.NewConn(conn, c, opts...),
		table:      "`onec_project_cluster`",
	}
}

func (m *defaultOnecProjectClusterModel) Delete(ctx context.Context, id uint64) error {
	data, err := m.FindOne(ctx, id)
	if err != nil {
		return err
	}

	ikubeopsOnecProjectClusterClusterUuidProjectIdKey := fmt.Sprintf("%s%v:%v", cacheIkubeopsOnecProjectClusterClusterUuidProjectIdPrefix, data.ClusterUuid, data.ProjectId)
	ikubeopsOnecProjectClusterIdKey := fmt.Sprintf("%s%v", cacheIkubeopsOnecProjectClusterIdPrefix, id)
	_, err = m.ExecCtx(ctx, func(ctx context.Context, conn sqlx.SqlConn) (result sql.Result, err error) {
		query := fmt.Sprintf("delete from %s where `id` = ?", m.table)
		return conn.ExecCtx(ctx, query, id)
	}, ikubeopsOnecProjectClusterClusterUuidProjectIdKey, ikubeopsOnecProjectClusterIdKey)
	return err
}

func (m *defaultOnecProjectClusterModel) DeleteSoft(ctx context.Context, id uint64) error {
	data, err := m.FindOne(ctx, id)
	if err != nil {
		return err
	}
	// 如果记录已软删除，无需再次删除
	if data.IsDeleted == 1 {
		return nil
	}
	ikubeopsOnecProjectClusterClusterUuidProjectIdKey := fmt.Sprintf("%s%v:%v", cacheIkubeopsOnecProjectClusterClusterUuidProjectIdPrefix, data.ClusterUuid, data.ProjectId)
	ikubeopsOnecProjectClusterIdKey := fmt.Sprintf("%s%v", cacheIkubeopsOnecProjectClusterIdPrefix, id)
	_, err = m.ExecCtx(ctx, func(ctx context.Context, conn sqlx.SqlConn) (result sql.Result, err error) {
		query := fmt.Sprintf("update %s set `is_deleted` = 1 where `id` = ?", m.table)
		return conn.ExecCtx(ctx, query, id)
	}, ikubeopsOnecProjectClusterClusterUuidProjectIdKey, ikubeopsOnecProjectClusterIdKey)
	return err
}

func (m *defaultOnecProjectClusterModel) TransCtx(ctx context.Context, fn func(context.Context, sqlx.Session) error) error {
	return m.TransactCtx(ctx, func(ctx context.Context, session sqlx.Session) error {
		return fn(ctx, session)
	})
}

func (m *defaultOnecProjectClusterModel) TransOnSql(ctx context.Context, session sqlx.Session, id uint64, sqlStr string, args ...any) (sql.Result, error) {
	query := strings.ReplaceAll(sqlStr, "{table}", m.table)
	// 如果 id != 0 并且启用了缓存逻辑
	if !isZeroValue(id) {
		// 查询数据（如果需要，确保数据存在）
		data, err := m.FindOne(ctx, id)
		if err != nil {
			return nil, err
		}

		// 缓存相关处理

		ikubeopsOnecProjectClusterClusterUuidProjectIdKey := fmt.Sprintf("%s%v:%v", cacheIkubeopsOnecProjectClusterClusterUuidProjectIdPrefix, data.ClusterUuid, data.ProjectId)
		ikubeopsOnecProjectClusterIdKey := fmt.Sprintf("%s%v", cacheIkubeopsOnecProjectClusterIdPrefix, id) // 处理缓存逻辑，例如删除或更新缓存
		// 执行带缓存处理的 SQL 操作
		return m.ExecCtx(ctx, func(ctx context.Context, conn sqlx.SqlConn) (sql.Result, error) {
			return session.ExecCtx(ctx, query, args...)
		}, ikubeopsOnecProjectClusterClusterUuidProjectIdKey, ikubeopsOnecProjectClusterIdKey) // 传递缓存相关的键值

	}

	// 如果 id == 0 或不需要缓存，直接执行 SQL
	return m.ExecCtx(ctx, func(ctx context.Context, conn sqlx.SqlConn) (sql.Result, error) {
		return session.ExecCtx(ctx, query, args...)
	})
}

func (m *defaultOnecProjectClusterModel) ExecSql(ctx context.Context, id uint64, sqlStr string, args ...any) (sql.Result, error) {
	// 如果 id != 0 并且启用了缓存逻辑
	query := strings.ReplaceAll(sqlStr, "{table}", m.table)
	if !isZeroValue(id) {
		// 缓存相关处理

		// 查询数据（如果需要，确保数据存在）
		data, err := m.FindOne(ctx, id)
		if err != nil {
			return nil, err
		}

		ikubeopsOnecProjectClusterClusterUuidProjectIdKey := fmt.Sprintf("%s%v:%v", cacheIkubeopsOnecProjectClusterClusterUuidProjectIdPrefix, data.ClusterUuid, data.ProjectId)
		ikubeopsOnecProjectClusterIdKey := fmt.Sprintf("%s%v", cacheIkubeopsOnecProjectClusterIdPrefix, id) // 处理缓存逻辑，例如删除或更新缓存
		// 执行带缓存处理的 SQL 操作
		return m.ExecCtx(ctx, func(ctx context.Context, conn sqlx.SqlConn) (sql.Result, error) {
			return conn.ExecCtx(ctx, query, args...)
		}, ikubeopsOnecProjectClusterClusterUuidProjectIdKey, ikubeopsOnecProjectClusterIdKey) // 传递缓存相关的键值

	}

	// 如果 id == 0 或不需要缓存，直接执行 SQL
	return m.ExecCtx(ctx, func(ctx context.Context, conn sqlx.SqlConn) (sql.Result, error) {
		return conn.ExecCtx(ctx, query, args...)
	})
}
func (m *defaultOnecProjectClusterModel) FindOne(ctx context.Context, id uint64) (*OnecProjectCluster, error) {
	ikubeopsOnecProjectClusterIdKey := fmt.Sprintf("%s%v", cacheIkubeopsOnecProjectClusterIdPrefix, id)
	var resp OnecProjectCluster
	err := m.QueryRowCtx(ctx, &resp, ikubeopsOnecProjectClusterIdKey, func(ctx context.Context, conn sqlx.SqlConn, v any) error {
		query := fmt.Sprintf("select %s from %s where `id` = ? AND `is_deleted` = 0 limit 1", onecProjectClusterRows, m.table)
		return conn.QueryRowCtx(ctx, v, query, id)
	})
	switch err {
	case nil:
		return &resp, nil
	case sqlc.ErrNotFound:
		return nil, ErrNotFound
	default:
		return nil, err
	}
}

func (m *defaultOnecProjectClusterModel) Search(ctx context.Context, orderStr string, isAsc bool, page, pageSize uint64, queryStr string, args ...any) ([]*OnecProjectCluster, uint64, error) {
	// 确保分页参数有效
	if page < 1 {
		page = 1
	}
	if pageSize < 1 {
		pageSize = 20
	}

	// 构造查询条件
	// 添加 `is_deleted` = 0 条件，保证只查询未软删除数据
	// 初始化 WHERE 子句
	where := "WHERE `is_deleted` = 0"
	if queryStr != "" {
		where = fmt.Sprintf("WHERE %s AND `is_deleted` = 0", queryStr)
	}

	// 根据 isAsc 参数确定排序方式
	sortDirection := "ASC"
	if !isAsc {
		sortDirection = "DESC"
	}

	// 如果用户未指定排序字段，则默认使用 id
	if orderStr == "" {
		orderStr = fmt.Sprintf("ORDER BY id %s", sortDirection)
	} else {
		orderStr = strings.TrimSpace(orderStr)
		if !strings.HasPrefix(strings.ToUpper(orderStr), "ORDER BY") {
			orderStr = "ORDER BY " + orderStr
		}
		orderStr = fmt.Sprintf("%s %s", orderStr, sortDirection)
	}

	countQuery := fmt.Sprintf("SELECT COUNT(1) FROM %s %s", m.table, where)

	var total uint64
	var resp []*OnecProjectCluster
	err := m.QueryRowNoCacheCtx(ctx, &total, countQuery, args...)
	if err != nil {
		return nil, 0, err
	}
	if total == 0 {
		// 无匹配记录
		return resp, 0, ErrNotFound
	}
	offset := (page - 1) * pageSize
	dataQuery := fmt.Sprintf("SELECT %s FROM %s %s %s LIMIT %d,%d", onecProjectClusterRows, m.table, where, orderStr, offset, pageSize)

	err = m.QueryRowsNoCacheCtx(ctx, &resp, dataQuery, args...)
	if err != nil {
		return nil, 0, err
	}

	return resp, total, nil
}

func (m *defaultOnecProjectClusterModel) SearchNoPage(ctx context.Context, orderStr string, isAsc bool, queryStr string, args ...any) ([]*OnecProjectCluster, error) {
	// 处理 nil 参数
	if args == nil {
		args = []any{}
	}
	// 初始化 WHERE 子句
	where := "WHERE `is_deleted` = 0"
	// 处理查询条件和参数
	var finalArgs []any
	if queryStr != "" {
		where = fmt.Sprintf("WHERE %s AND `is_deleted` = 0", queryStr)
		// 只有当有查询条件时才使用参数
		if len(args) > 0 {
			finalArgs = args
		}
	}

	// 根据 isAsc 参数确定排序方式
	sortDirection := "ASC"
	if !isAsc {
		sortDirection = "DESC"
	}
	// 如果用户未指定排序字段，则默认使用 id
	if orderStr == "" {
		orderStr = fmt.Sprintf("ORDER BY id %s", sortDirection)
	} else {
		orderStr = strings.TrimSpace(orderStr)
		if !strings.HasPrefix(strings.ToUpper(orderStr), "ORDER BY") {
			orderStr = "ORDER BY " + orderStr
		}
		orderStr = fmt.Sprintf("%s %s", orderStr, sortDirection)
	}
	dataQuery := fmt.Sprintf("SELECT %s FROM %s %s %s", onecProjectClusterRows, m.table, where, orderStr)
	var resp []*OnecProjectCluster
	// 根据是否有参数来调用
	var err error
	if len(finalArgs) > 0 {
		err = m.QueryRowsNoCacheCtx(ctx, &resp, dataQuery, finalArgs...)
	} else {
		err = m.QueryRowsNoCacheCtx(ctx, &resp, dataQuery)
	}
	switch err {
	case nil:
		return resp, nil
	case sqlx.ErrNotFound:
		return nil, ErrNotFound
	default:
		return nil, err
	}
}
func (m *defaultOnecProjectClusterModel) FindOneByClusterUuidProjectId(ctx context.Context, clusterUuid string, projectId uint64) (*OnecProjectCluster, error) {
	ikubeopsOnecProjectClusterClusterUuidProjectIdKey := fmt.Sprintf("%s%v:%v", cacheIkubeopsOnecProjectClusterClusterUuidProjectIdPrefix, clusterUuid, projectId)
	var resp OnecProjectCluster
	err := m.QueryRowIndexCtx(ctx, &resp, ikubeopsOnecProjectClusterClusterUuidProjectIdKey, m.formatPrimary, func(ctx context.Context, conn sqlx.SqlConn, v any) (i any, e error) {
		query := fmt.Sprintf("select %s from %s where `cluster_uuid` = ? and `project_id` = ? AND `is_deleted` = 0  limit 1", onecProjectClusterRows, m.table)
		if err := conn.QueryRowCtx(ctx, &resp, query, clusterUuid, projectId); err != nil {
			return nil, err
		}
		return resp.Id, nil
	}, m.queryPrimary)
	switch err {
	case nil:
		return &resp, nil
	case sqlc.ErrNotFound:
		return nil, ErrNotFound
	default:
		return nil, err
	}
}

func (m *defaultOnecProjectClusterModel) Insert(ctx context.Context, data *OnecProjectCluster) (sql.Result, error) {
	ikubeopsOnecProjectClusterClusterUuidProjectIdKey := fmt.Sprintf("%s%v:%v", cacheIkubeopsOnecProjectClusterClusterUuidProjectIdPrefix, data.ClusterUuid, data.ProjectId)
	ikubeopsOnecProjectClusterIdKey := fmt.Sprintf("%s%v", cacheIkubeopsOnecProjectClusterIdPrefix, data.Id)
	ret, err := m.ExecCtx(ctx, func(ctx context.Context, conn sqlx.SqlConn) (result sql.Result, err error) {
		query := fmt.Sprintf("insert into %s (%s) values (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)", m.table, onecProjectClusterRowsExpectAutoSet)
		return conn.ExecCtx(ctx, query, data.ClusterUuid, data.ProjectId, data.CpuLimit, data.CpuOvercommitRatio, data.CpuCapacity, data.CpuAllocated, data.MemLimit, data.MemOvercommitRatio, data.MemCapacity, data.MemAllocated, data.StorageLimit, data.StorageAllocated, data.GpuLimit, data.GpuOvercommitRatio, data.GpuCapacity, data.GpuAllocated, data.PodsLimit, data.PodsAllocated, data.ConfigmapLimit, data.ConfigmapAllocated, data.SecretLimit, data.SecretAllocated, data.PvcLimit, data.PvcAllocated, data.EphemeralStorageLimit, data.EphemeralStorageAllocated, data.ServiceLimit, data.ServiceAllocated, data.LoadbalancersLimit, data.LoadbalancersAllocated, data.NodeportsLimit, data.NodeportsAllocated, data.DeploymentsLimit, data.DeploymentsAllocated, data.JobsLimit, data.JobsAllocated, data.CronjobsLimit, data.CronjobsAllocated, data.DaemonsetsLimit, data.DaemonsetsAllocated, data.StatefulsetsLimit, data.StatefulsetsAllocated, data.IngressesLimit, data.IngressesAllocated, data.CreatedBy, data.UpdatedBy, data.IsDeleted)
	}, ikubeopsOnecProjectClusterClusterUuidProjectIdKey, ikubeopsOnecProjectClusterIdKey)
	return ret, err
}

func (m *defaultOnecProjectClusterModel) Update(ctx context.Context, newData *OnecProjectCluster) error {
	data, err := m.FindOne(ctx, newData.Id)
	if err != nil {
		return err
	}

	ikubeopsOnecProjectClusterClusterUuidProjectIdKey := fmt.Sprintf("%s%v:%v", cacheIkubeopsOnecProjectClusterClusterUuidProjectIdPrefix, data.ClusterUuid, data.ProjectId)
	ikubeopsOnecProjectClusterIdKey := fmt.Sprintf("%s%v", cacheIkubeopsOnecProjectClusterIdPrefix, data.Id)
	_, err = m.ExecCtx(ctx, func(ctx context.Context, conn sqlx.SqlConn) (result sql.Result, err error) {
		query := fmt.Sprintf("update %s set %s where `id` = ?", m.table, onecProjectClusterRowsWithPlaceHolder)
		return conn.ExecCtx(ctx, query, newData.ClusterUuid, newData.ProjectId, newData.CpuLimit, newData.CpuOvercommitRatio, newData.CpuCapacity, newData.CpuAllocated, newData.MemLimit, newData.MemOvercommitRatio, newData.MemCapacity, newData.MemAllocated, newData.StorageLimit, newData.StorageAllocated, newData.GpuLimit, newData.GpuOvercommitRatio, newData.GpuCapacity, newData.GpuAllocated, newData.PodsLimit, newData.PodsAllocated, newData.ConfigmapLimit, newData.ConfigmapAllocated, newData.SecretLimit, newData.SecretAllocated, newData.PvcLimit, newData.PvcAllocated, newData.EphemeralStorageLimit, newData.EphemeralStorageAllocated, newData.ServiceLimit, newData.ServiceAllocated, newData.LoadbalancersLimit, newData.LoadbalancersAllocated, newData.NodeportsLimit, newData.NodeportsAllocated, newData.DeploymentsLimit, newData.DeploymentsAllocated, newData.JobsLimit, newData.JobsAllocated, newData.CronjobsLimit, newData.CronjobsAllocated, newData.DaemonsetsLimit, newData.DaemonsetsAllocated, newData.StatefulsetsLimit, newData.StatefulsetsAllocated, newData.IngressesLimit, newData.IngressesAllocated, newData.CreatedBy, newData.UpdatedBy, newData.IsDeleted, newData.Id)
	}, ikubeopsOnecProjectClusterClusterUuidProjectIdKey, ikubeopsOnecProjectClusterIdKey)
	return err
}

func (m *defaultOnecProjectClusterModel) formatPrimary(primary any) string {
	return fmt.Sprintf("%s%v", cacheIkubeopsOnecProjectClusterIdPrefix, primary)
}

func (m *defaultOnecProjectClusterModel) queryPrimary(ctx context.Context, conn sqlx.SqlConn, v, primary any) error {
	query := fmt.Sprintf("select %s from %s where `id` = ? AND `is_deleted` = 0 limit 1", onecProjectClusterRows, m.table)
	return conn.QueryRowCtx(ctx, v, query, primary)
}

func (m *defaultOnecProjectClusterModel) tableName() string {
	return m.table
}
